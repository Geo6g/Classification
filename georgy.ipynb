{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Geo6g/Classification/blob/main/georgy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "pJqjsUwWv1yz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('churn_data.csv')"
      ],
      "metadata": {
        "id": "P5pI7EjAwpOh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "c8a495fd-80e0-4ee2-86ba-a08fa9474659"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'churn_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3375390580.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'churn_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'churn_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n"
      ],
      "metadata": {
        "id": "T4GihXeZxbGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "id": "mvqcFw87xghy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "P08VyJ5LzE0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "5vwD-mR03wsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "EWUMBQnV38c5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = {}\n",
        "for col in df.select_dtypes(include=['object']):\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoder[col] = le"
      ],
      "metadata": {
        "id": "df8ibLRi41Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns.drop('churn')\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])"
      ],
      "metadata": {
        "id": "843JNdlt43kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "7npqqo_d5gBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='churn', data=df)\n",
        "plt.title('Churn Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JZItMfAp5w06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.corr(), annot=True)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4Q08Cdfb590Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x='churn', y='satisfaction', data=df)\n",
        "plt.title('Satisfaction vs Churn')\n",
        "plt.xlabel('Churn')\n",
        "plt.ylabel('Satisfaction')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nJkIWl1kCu4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "xC_fwwPj6NeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.drop('churn',axis=1)\n",
        "y=df['churn']"
      ],
      "metadata": {
        "id": "qlxQbAuo6kZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "z7YiWMJV6np5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models={\n",
        "    'Logistic Regression':LogisticRegression(),\n",
        "    'Random Forest':RandomForestClassifier(),\n",
        "    'Decision Tree':DecisionTreeClassifier()\n",
        "}"
      ],
      "metadata": {
        "id": "tWMCmgm36qZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name,model in models.items():\n",
        "    model.fit(X_train,y_train)\n",
        "    print(f'{name} Accuracy:{model.score(X_test,y_test):.2f}')"
      ],
      "metadata": {
        "id": "bHr1d3cT6vFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100],\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_split': [2],\n",
        "    'min_samples_leaf': [1],\n",
        "    'bootstrap': [True]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf_grid_search = GridSearchCV(estimator=rf, param_grid=rf_param_grid,cv=5,verbose=1,n_jobs=-1)\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "print(\"Best Random Forest Parameters:\", rf_grid_search.best_params_)"
      ],
      "metadata": {
        "id": "9JjGc0dq7DqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']  # Only solver supporting both l1 and l2\n",
        "}\n",
        "\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "lr_grid_search = GridSearchCV(estimator=lr,\n",
        "                              param_grid=lr_param_grid,\n",
        "                              cv=5,\n",
        "                              verbose=1,\n",
        "                              n_jobs=-1)\n",
        "\n",
        "lr_grid_search.fit(X_train, y_train)\n",
        "print(\"Best Logistic Regression Parameters:\", lr_grid_search.best_params_)"
      ],
      "metadata": {
        "id": "mO7s1K5S8NmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "bthxaOrf9DjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf = rf_grid_search.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "print(\" Random Forest\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "zMiR6Moa9HBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_lr = lr_grid_search.best_estimator_\n",
        "y_pred_lr = best_lr.predict(X_test)\n",
        "\n",
        "print(\" Logistic Regression\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "id": "UyOf8Bis9IyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_default = DecisionTreeClassifier(random_state=42)\n",
        "dt_default.fit(X_train, y_train)\n",
        "y_pred_dt = dt_default.predict(X_test)\n",
        "\n",
        "print(\" Decision Tree (Default)\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(classification_report(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "id": "hcn_awgh9M7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "models = ['Random Forest', 'Decision Tree', 'Logistic Regression']\n",
        "accuracies = [0.9892, 0.9771, 0.7601]\n",
        "\n",
        "plt.bar(models, accuracies, color=['green', 'blue', 'red'])\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lgCRHQ_K9rfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_rf = rf_grid_search.best_estimator_.score(X_test, y_test)\n",
        "acc_lr = lr_grid_search.best_estimator_.score(X_test, y_test)\n",
        "acc_dt = DecisionTreeClassifier(random_state=42).fit(X_train, y_train).score(X_test, y_test)\n",
        "accuracies = {\n",
        "    'Random Forest': acc_rf,\n",
        "    'Logistic Regression': acc_lr,\n",
        "    'Decision Tree': acc_dt\n",
        "}\n",
        "best_model = max(accuracies, key=accuracies.get)\n",
        "print(f\"Best model is: {best_model} with accuracy: {accuracies[best_model]:.4f}\")"
      ],
      "metadata": {
        "id": "lV2dFjsd-N5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_selected = X_test.iloc[[92, 93]]\n",
        "\n",
        "\n",
        "y_pred = best_rf.predict(X_selected)\n",
        "y_proba = best_rf.predict_proba(X_selected)[:, 1]\n",
        "\n",
        "\n",
        "for i, idx in enumerate([92, 93]):\n",
        "    print(f\"\\nSample {idx}\")\n",
        "    print(X_selected.iloc[i])\n",
        "    print(\" Prediction:\", \"Churn\" if y_pred[i] == 1 else \"No Churn\")\n",
        "    print(f\" Probability of Churn: {y_proba[i]:.2f}\")\n"
      ],
      "metadata": {
        "id": "T94vNes5BbVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Random Forest was the most accurate model for predicting churn, outperforming\n",
        " Logistic Regression and Decision Tree.\n",
        "\n",
        " Low satisfaction level and longer tenure were strong indicators of higher employee churn.\n",
        "\n",
        " Encoded categorical features (department, salary) and normalized numerical data were used for model training.\n",
        "\n",
        "Sample predictions showed reliable performance, with churn probabilities giving clear risk insights.\n",
        "\n"
      ],
      "metadata": {
        "id": "ikvR5qCME-8w"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}